* make ioat recv medium asynchronous, post it earlier, wait it later

* error handler when completing zombie send/recv only if ep totally open, with special message

* register_unexp_callback wrapper

* replace pull handle's BH lock + idr with RCU + array ?

* limit the number of pull/send_large to avoid deadlock caused by 255 rdma windows

* add a counter of failure to register with ENOMEM and abort if too many?
  + move to a different queue so that it does not prevent other queued req from being processed?

* 64bit internals by default
* 64bit API by default, unless OMX_32BITS_LENGTH is defined
  + how to force the #define OMX_32BITS_LENGTH once compiled and installed?

* endpoint parameters
  + unexp queue length

* document cpu/irq binding

* improve retransmission
  + don't free partner since we can't change the session anymore?
    - or randomify the initial session?

* thread safety
  + filter wakeup on recv/send/connect/...
  + filter on specific request id too
  + progress thread only woken up if nobody else
  + split the progression timer out of the timeout timer and make it global
    and wakeup a single process
  + change the wakeup_jiffies mapped value into an ioctl parameter?

* when debug enabled, SIGUSR1 dumps the status

* unlockify the ring management in the driver event reporting code
  + use rcu to avoid having to lock the waiter's queue
    - allocate the waiter struct and free it with a rcu_call
  + atomic_test_and_set instead of spinlock to get a event slot? what about recv slot?
    ok if lots of slices in parallel ?
  + add a driver-private field in event where the reporter will test_and_set BUSY
    before posting the event and finally posting the type and removing BUSY

* group similar fields in structure for cache effects

* free request (and buffers) on close
  + preallocated pool with free list
  + cleanup request to avoid below when killing during large
    send failed with status (Endpoint Closed)
    omx_pingpong: /home/bgoglin/open-mx/build-x86_64/../src/libopen-mx/omx_large.c:96: 
    omx__endpoint_large_region_free: Assertion `array[index].region.use_count == 0' failed.

* drop our region window offset ? (when wire compat will work for large)
  + pull are aligned on the reader's pages because it's the slower side on native MX
    - we don't really care about alignment in open-mx, pages are pinned first, adding 2 pages to a skb isn't very expensive
    - we will still follow the remote side requirements when pulling from MX
    - MX doesn't care about our alignement when it pulls from us
  + design is ugly (fixed in 1.3?)

* skb_clone and alloc_skb_fclone for pull and pull replies?
* netif_wake_queue(dev) after xmit?

* prefetch non-temporal from the event ring ro prevent cache line bounces?
* or write event with non-temporal? hard in the kernel

* --enable-32b/64b

* get info irq affinity

* factorize early and msg seqnum index computing (cache them?)

* wire compat
  + what's in src_generation ? unset/unchecked in OMX
  + no rdmawin_seqnum set/checked
  + lib ack contents
* wire-compat at runtime

* optimize mediums
  + 2 pages if not mx wire compat
    - double the recv queue size
  + single ioctl, pipeline get_user_pages/dev_queue_xmit, put_pages in the last callback

* pull improvements
  + ph_prepare_exit only called when holding the iface mutex, may sleep
    - but last_release may be called from interrupt context

* use large region id in the lib, only allocate uint8_t id for the wire when
  posting the rndv message or the pull request
* overlap registration with rndv and pull
  + mark the window as valid but not ready during registration
  + drop the pull request if it arrives
  + make the window status consistent during registration so that first pages
    may be used while the end is not registered yet
* export rdma_get and rdma window management functions
* rdma_put
* write parameter in ioctl to register a region, check it when reading/writing from/to the region

* move recv lib in the kernel
  + limit unexpq size to avoid memory starvation
    - or allocate default unexp buffers upto 32kB
    - use a usual recv queue for unexp?
  + need to keep partner's recv_seqnum in the kernel
    - and synchronize with user-space which takes care of acking
    - share mapping of peer-index based array of recv seqnums between kernel and user-space?

* add warning about mtu in nic/switches when truncated packet arrives, with printk_rate

* mapper (open-mxd)
* /dev/open-mxd ?

* use IOAT
  + post a req
    cookie = dma_async_memcpy_pg_to_pg(chan, dst_page, dest_off, src_page, src_off, len)
  + send a batch of req
    dma_async_memcpy_issue_pending(chan)
  + poll completion of one cookie foo:
    dma_async_memcpy_complete(chan, cookie, NULL, NULL) == DMA_SUCCESS
  + poll completion up to last_cookie (see tcp_recvmsg() in net/ipv4/tcp.c)
    while dma_async_memcpy_complete(chan, last_cookie, &done, &used) == DMA_IN_PROGRESS
      while dma_async_is_complete(next_cookie, done, used) == DMA_SUCCESS
        free next_cookie's skb
    free all skb up to last_cookie
  + get/release a chan
    chan = get_softnet_dma()
    ...
    dma_chan_put(chan)
  + manage client/chan (see netdev_dma_event() net/core/dev.c)
    struct dma_client client.event_callback
    dma_async_client_register(client)
    dma_async_client_chan_request(client)
  + for recv large, wait for the last completion before reporting pull 
    done completion. or send copy the last frag manually without IOAT
  + for medium, how to report an event and wakeup userspace efficiently
    if we are not notified of the IOAT completion end?
  + might be easier medium with kernel matching?
