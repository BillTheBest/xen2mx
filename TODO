* release 0.4.90 with ioat disable for now to get bug fix and new ABI out
  without fixing everything else

* corruption?
  + corruption in mx_msg_loop in the last frame of the first block whne multiple instanes in parallel

* fix/improve ioat support
  + sleep a bit before polling on synchronous copies
    - add an empirical ioat speed, tested at startup, tuned at runtime, configurable with a module param
    - use the empirical ioat speed to sleep using msleep during large 
      synchronous copy instead of polling
    - if copy completed on first poll, increase the speed by 12.5% or so
    - no need to reduce the speed ever

* support non-ethernet networks by providing ways to extract the mac address differently
  + infiniband ifaces have too small mtu?

* fix/improve large messages
  + regcache malloc hook
  + replace pull handle's BH lock + idr with RCU + array ?
  + split and move the pull handle bitmask into the handle descriptors
    - add a "valid" bit to easily detect when the second block is done before the first one
  + have more pull block at the same time, at least 4?
    - makes 31 frame per block useless?
  + if pulling few packet, using multiple request with small blocks to 
    parallelize the processing of multiple blocks on the remote side ?
  + ph_prepare_exit only called when holding the iface mutex, may sleep
    - but last_release may be called from interrupt context

* shared
  + reduce large threshold for shared? only if ioat enabled?
    - user-space doesn't know about it, add a hint in the driver desc?
  + why shared memory from/to same send and recv buffer is very bad from 64k+ 128k ?

* website
  + add a section about performance numbers on the website, with I/O AT numbers
    and link to the performance tuning section of the README

* affinity
  + add ioctls GET_BOARD_CPUMASK and GET_IRQ_CPUMASK
  + add OMX_BIND=irq/board/<mask>
  + add OMX_ENDPOINT_MSIX_BASE=

* error handler when completing zombie send/recv only if ep totally open, with special message

* overlap registration with rndv and pull
  + add a "registered_length" field to windows
  + add a delayed register field to register req, only alloc struct, do not pin
  + add a need register field to rndv and pull with a window number
  + queue skb if touching after the registered_length
    - dequeue after registering enough
  + register by blocks (8 or 16 pages per block)
  + let shared comm poll until the window is large enough
  + remove the user-space knowledge of window being registered for real
    - integrate into mmu notifier since there is no need anymore to notify userspace when region is invalidated

* add flags for all queued state and split throttling/queued queue into per-flag queue
  + let the callee requeue and return need_retry if did not queue to a better queue
  + and use them and completing requests
  + need memory for small
    - add a counter of failure to register with ENOMEM and abort if too many?
  + need exp events for medium and pull
  + need sendq slots for medium
  + need region for send large without deadlock
  + need region for recv large
  + need system resources for send large and recv large
    - add a counter of failure to register with ENOMEM and abort if too many?

* feature flags in the driver descriptor to check an extended abi version
  + enforce shared support?

* 64bit internals by default
* 64bit API by default, unless OMX_32BITS_LENGTH is defined
  + how to force the #define OMX_32BITS_LENGTH once compiled and installed?

* look at vringfd (http://lwn.net/Articles/276364/) to replace event ring

* endpoint parameters
  + unexp queue length

* improve retransmission
  + don't free partner since we can't change the session anymore?
    - or randomify the initial session?

* thread safety
  + filter wakeup on recv/send/connect/...
  + filter on specific request id too
  + progress thread only woken up if nobody else
  + split the progression timer out of the timeout timer and make it global
    and wakeup a single process
  + change the wakeup_jiffies mapped value into an ioctl parameter?

* when debug enabled, SIGUSR1 dumps the status

* unlockify the ring management in the driver event reporting code
  + use rcu to avoid having to lock the waiter's queue
    - allocate the waiter struct and free it with a rcu_call
  + atomic_test_and_set instead of spinlock to get a event slot? what about recv slot?
    ok if lots of slices in parallel ?
  + add a driver-private field in event where the reporter will test_and_set BUSY
    before posting the event and finally posting the type and removing BUSY
  + per cpu rings? not scalable with number of cups
  + prefetch non-temporal from the event ring ro prevent cache line bounces?
  + or write event with non-temporal? hard in the kernel

* group similar fields in structure for cache effects

* free request (and buffers) on close
  + preallocated pool with free list
  + cleanup request to avoid below when killing during large
    send failed with status (Endpoint Closed)
    omx_pingpong: /home/bgoglin/open-mx/build-x86_64/../src/libopen-mx/omx_large.c:96: 
    omx__endpoint_large_region_free: Assertion `array[index].region.use_count == 0' failed.

* drop our region window offset ? (when wire compat will work for large)
  + pull are aligned on the reader's pages because it's the slower side on native MX
    - we don't really care about alignment in open-mx, pages are pinned first, adding 2 pages to a skb isn't very expensive
    - we will still follow the remote side requirements when pulling from MX
    - MX doesn't care about our alignement when it pulls from us
  + design is ugly (fixed in 1.3?)

* skb_clone and alloc_skb_fclone for pull and pull replies?
* netif_wake_queue(dev) after xmit?

* --enable-32b/64b

* get info irq affinity

* wire compat
  + what's in src_generation ? unset/unchecked in OMX
  + no rdmawin_seqnum set/checked
  + lib ack contents
* wire-compat at runtime?
  + once reply-per-block is useless thanks to more blocks in parallel

* optimize mediums
  + 2 pages if not mx wire compat
    - double the recv queue size
  + single ioctl, pipeline get_user_pages/dev_queue_xmit, put_pages in the last callback

* use large region id in the lib, only allocate uint8_t id for the wire when
  posting the rndv message or the pull request
* export rdma_get and rdma window management functions
* rdma_put
* write parameter in ioctl to register a region, check it when reading/writing from/to the region
  + different rdmawin id for sender/receiver
    - no need to check for deadlock if too many sender's rdmawin registered

* move recv lib in the kernel
  + early ioatcopy expected medium, move the other in the recv ring, drop when no space anymore
    - keep unexpected data in the ring for ever
    - when unexpected is posted, notify the kernel that we acquired the ring slots and let it
      finish receiving in the target buffer
  + limit unexpq size to avoid memory starvation
    - or allocate default unexp buffers upto 32kB
    - use a usual recv queue for unexp?
  + need to keep partner's recv_seqnum in the kernel
    - and synchronize with user-space which takes care of acking
    - share mapping of peer-index based array of recv seqnums between kernel and user-space?
  + use ioat to offload the whole recv medium copy and wait in the last frag
  + move the whole lib in the driver and only keep basic request status in userspace?

* add warning about mtu in nic/switches when truncated packet arrives, with printk_rate

* mapper (open-mxd)
* /dev/open-mxd ?

* per-packet-type irq
  + can we detect when another packet is right behind? if so, process it
    and queue the early interrupt if it is not a small one
